{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Linear regression on real world data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 925, 'name': 'Infrared Thermography Temperature', 'repository_url': 'https://archive.ics.uci.edu/dataset/925/infrared+thermography+temperature+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/925/data.csv', 'abstract': 'The Infrared Thermography Temperature Dataset contains temperatures read from various locations of inferred images about patients, with the addition of oral temperatures measured for each individual. The 33 features consist of gender, age, ethnicity, ambiant temperature, humidity, distance, and other temperature readings from the thermal images. The dataset is intended to be used in a regression task to predict the oral temperature using the environment information as well as the thermal image readings. ', 'area': 'Health and Medicine', 'tasks': ['Regression'], 'characteristics': ['Tabular'], 'num_instances': 1020, 'num_features': 33, 'feature_types': ['Real', 'Categorical'], 'demographics': ['Gender', 'Age', 'Ethnicity'], 'target_col': ['aveOralF', 'aveOralM'], 'index_col': ['SubjectID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2021, 'last_updated': 'Tue Dec 12 2023', 'dataset_doi': '10.13026/9ay4-2c37', 'creators': ['Quanzeng Wang', 'Yangling Zhou', 'Pejman Ghassemi', 'David McBride', 'J. Casamento', 'T. Pfefer', 'Quanzeng Wang', 'Yangling Zhou', 'Pejman Ghassemi', 'David McBride', 'J. Casamento', 'T. Pfefer'], 'intro_paper': {'title': 'Infrared Thermography for Measuring Elevated Body Temperature: Clinical Accuracy, Calibration, and Evaluation', 'authors': 'Quanzeng Wang, Yangling Zhou, Pejman Ghassemi, David McBride, J. Casamento, T. Pfefer', 'published_in': 'Italian National Conference on Sensors', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/443b9932d295ca3a014e7d874b4bd77a33a276bd', 'doi': None}, 'additional_info': {'summary': None, 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '- gender\\n- age\\n- ethnicity\\n- ambiant temperature\\n- humidity\\n- distance\\n- temperature readings from the thermal images', 'citation': None}, 'external_url': 'https://physionet.org/content/face-oral-temp-data/1.0.0/'}\n",
      "           name     role         type demographic  \\\n",
      "0     SubjectID       ID  Categorical        None   \n",
      "1      aveOralF   Target   Continuous        None   \n",
      "2      aveOralM   Target   Continuous        None   \n",
      "3        Gender  Feature  Categorical      Gender   \n",
      "4           Age  Feature  Categorical         Age   \n",
      "5     Ethnicity  Feature  Categorical   Ethnicity   \n",
      "6         T_atm  Feature   Continuous        None   \n",
      "7      Humidity  Feature   Continuous        None   \n",
      "8      Distance  Feature   Continuous        None   \n",
      "9     T_offset1  Feature   Continuous        None   \n",
      "10    Max1R13_1  Feature   Continuous        None   \n",
      "11    Max1L13_1  Feature   Continuous        None   \n",
      "12  aveAllR13_1  Feature   Continuous        None   \n",
      "13  aveAllL13_1  Feature   Continuous        None   \n",
      "14        T_RC1  Feature   Continuous        None   \n",
      "15    T_RC_Dry1  Feature   Continuous        None   \n",
      "16    T_RC_Wet1  Feature   Continuous        None   \n",
      "17    T_RC_Max1  Feature   Continuous        None   \n",
      "18        T_LC1  Feature   Continuous        None   \n",
      "19    T_LC_Dry1  Feature   Continuous        None   \n",
      "20    T_LC_Wet1  Feature   Continuous        None   \n",
      "21    T_LC_Max1  Feature   Continuous        None   \n",
      "22         RCC1  Feature   Continuous        None   \n",
      "23         LCC1  Feature   Continuous        None   \n",
      "24   canthiMax1  Feature   Continuous        None   \n",
      "25  canthi4Max1  Feature   Continuous        None   \n",
      "26      T_FHCC1  Feature   Continuous        None   \n",
      "27      T_FHRC1  Feature   Continuous        None   \n",
      "28      T_FHLC1  Feature   Continuous        None   \n",
      "29      T_FHBC1  Feature   Continuous        None   \n",
      "30      T_FHTC1  Feature   Continuous        None   \n",
      "31    T_FH_Max1  Feature   Continuous        None   \n",
      "32   T_FHC_Max1  Feature   Continuous        None   \n",
      "33       T_Max1  Feature   Continuous        None   \n",
      "34        T_OR1  Feature   Continuous        None   \n",
      "35    T_OR_Max1  Feature   Continuous        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                          Subject ID  None             no  \n",
      "1              Oral temperature measured in fast mode  None             no  \n",
      "2           Oral temperature measured in monitor mode  None             no  \n",
      "3                                      Male or Female  None             no  \n",
      "4                          Age ranges in categories\\n  None             no  \n",
      "5   American Indian or Alaska Native, Asian, Black...  None             no  \n",
      "6                                 Ambiant temperature  None             no  \n",
      "7                                   Relative humidity  None             no  \n",
      "8       Distance between the subjects and the IRTs.    None             no  \n",
      "9   Temperature difference between the set and mea...  None             no  \n",
      "10  Max value of a circle with diameter of 13 pixe...  None             no  \n",
      "11  Max value of a circle with diameter of 13 pixe...  None             no  \n",
      "12  Average value of a circle with diameter of 13 ...  None             no  \n",
      "13  Average value of a circle with diameter of 13 ...  None             no  \n",
      "14  Average temperature of the highest four pixels...  None             no  \n",
      "15  Average temperature of the highest four pixels...  None             no  \n",
      "16  Average temperature of the highest four pixels...  None             no  \n",
      "17  Max value of a square of 24x24 pixels around t...  None             no  \n",
      "18  Average temperature of the highest four pixels...  None             no  \n",
      "19  Average temperature of the highest four pixels...  None             no  \n",
      "20  Average temperature of the highest four pixels...  None             no  \n",
      "21  Max value of a circle with diameter of 13 pixe...  None             no  \n",
      "22  Average value of a square of 3x3 pixels center...  None             no  \n",
      "23  Average value of a square of 3x3 pixels center...  None             no  \n",
      "24              Max value in the extended canthi area  None             no  \n",
      "25  Average temperature of the highest four pixels...  None             no  \n",
      "26  Average value in the center point of forehead,...  None             no  \n",
      "27  Average value in the right point of the forehe...  None             no  \n",
      "28  Average value in the left point of the forehea...  None             no  \n",
      "29  Average value in the bottom point of the foreh...  None             no  \n",
      "30  Average value in the top point of the forehead...  None             no  \n",
      "31  Maximum temperature within the extended forehe...  None             no  \n",
      "32  Max value in the center point of forehead, a s...  None             no  \n",
      "33  Maximum temperature within the whole face region.  None             no  \n",
      "34  Average temperature of the highest four pixels...  None             no  \n",
      "35       Maximum temperature within the mouth region.  None             no  \n"
     ]
    }
   ],
   "source": [
    "# If package not installed, install it using pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "infrared_thermography_temperature = fetch_ucirepo(id=925)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = infrared_thermography_temperature.data.features\n",
    "y = infrared_thermography_temperature.data.targets\n",
    "\n",
    "# metadata\n",
    "print(infrared_thermography_temperature.metadata)\n",
    "\n",
    "# variable information\n",
    "print(infrared_thermography_temperature.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Independent and Dependent Variables\n",
    "- Independent variables: These are the features in X.\n",
    "- Dependent variables: These are the target values in y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids':       SubjectID\n",
      "0      161117-1\n",
      "1      161117-2\n",
      "2      161117-3\n",
      "3      161117-4\n",
      "4      161117-5\n",
      "...         ...\n",
      "1015  180425-05\n",
      "1016  180425-06\n",
      "1017  180502-01\n",
      "1018  180507-01\n",
      "1019  180514-01\n",
      "\n",
      "[1020 rows x 1 columns], 'features':       Gender    Age                  Ethnicity  T_atm  Humidity  Distance  \\\n",
      "0       Male  41-50                      White   24.0      28.0       0.8   \n",
      "1     Female  31-40  Black or African-American   24.0      26.0       0.8   \n",
      "2     Female  21-30                      White   24.0      26.0       0.8   \n",
      "3     Female  21-30  Black or African-American   24.0      27.0       0.8   \n",
      "4       Male  18-20                      White   24.0      27.0       0.8   \n",
      "...      ...    ...                        ...    ...       ...       ...   \n",
      "1015  Female  21-25                      Asian   25.7      50.8       0.6   \n",
      "1016  Female  21-25                      White   25.7      50.8       0.6   \n",
      "1017  Female  18-20  Black or African-American   28.0      24.3       0.6   \n",
      "1018    Male  26-30            Hispanic/Latino   25.0      39.8       0.6   \n",
      "1019  Female  18-20                      White   23.8      45.6       0.6   \n",
      "\n",
      "      T_offset1  Max1R13_1  Max1L13_1  aveAllR13_1  ...  T_FHCC1  T_FHRC1  \\\n",
      "0        0.7025    35.0300    35.3775      34.4000  ...  33.5775  33.4775   \n",
      "1        0.7800    34.5500    34.5200      33.9300  ...  34.0325  34.0550   \n",
      "2        0.8625    35.6525    35.5175      34.2775  ...  34.9000  34.8275   \n",
      "3        0.9300    35.2225    35.6125      34.3850  ...  34.4400  34.4225   \n",
      "4        0.8950    35.5450    35.6650      34.9100  ...  35.0900  35.1600   \n",
      "...         ...        ...        ...          ...  ...      ...      ...   \n",
      "1015     1.2225    35.6425    35.6525      34.8575  ...  35.1075  35.3475   \n",
      "1016     1.4675    35.9825    35.7575      35.4275  ...  35.3100  35.2175   \n",
      "1017     0.1300    36.4075    36.3400      35.8700  ...  35.4350  35.2400   \n",
      "1018     1.2450    35.8150    35.5250      34.2950  ...  34.8400  35.0200   \n",
      "1019     0.8675    35.7075    35.5825      34.8875  ...  34.5475  34.6500   \n",
      "\n",
      "      T_FHLC1  T_FHBC1  T_FHTC1  T_FH_Max1  T_FHC_Max1   T_Max1    T_OR1  \\\n",
      "0     33.3725  33.4925  33.0025    34.5300     34.0075  35.6925  35.6350   \n",
      "1     33.6775  33.9700  34.0025    34.6825     34.6600  35.1750  35.0925   \n",
      "2     34.6475  34.8200  34.6700    35.3450     35.2225  35.9125  35.8600   \n",
      "3     34.6550  34.3025  34.9175    35.6025     35.3150  35.7200  34.9650   \n",
      "4     34.3975  34.6700  33.8275    35.4175     35.3725  35.8950  35.5875   \n",
      "...       ...      ...      ...        ...         ...      ...      ...   \n",
      "1015  35.4000  35.1375  35.2750    35.8525     35.7475  36.0675  35.6775   \n",
      "1016  35.2200  35.2075  35.0700    35.7650     35.5525  36.5000  36.4525   \n",
      "1017  35.2275  35.3675  35.3425    36.3750     35.7100  36.5350  35.9650   \n",
      "1018  34.9250  34.7150  34.5950    35.4150     35.3100  35.8600  35.4150   \n",
      "1019  34.6700  34.2150  34.7100    35.1525     35.1175  35.9725  35.8900   \n",
      "\n",
      "      T_OR_Max1  \n",
      "0       35.6525  \n",
      "1       35.1075  \n",
      "2       35.8850  \n",
      "3       34.9825  \n",
      "4       35.6175  \n",
      "...         ...  \n",
      "1015    35.7100  \n",
      "1016    36.4900  \n",
      "1017    35.9975  \n",
      "1018    35.4350  \n",
      "1019    35.9175  \n",
      "\n",
      "[1020 rows x 33 columns], 'targets':       aveOralF  aveOralM\n",
      "0        36.85     36.59\n",
      "1        37.00     37.19\n",
      "2        37.20     37.34\n",
      "3        36.85     37.09\n",
      "4        36.80     37.04\n",
      "...        ...       ...\n",
      "1015     36.95     36.99\n",
      "1016     37.25     37.19\n",
      "1017     37.35     37.59\n",
      "1018     37.15     37.29\n",
      "1019     37.05     37.19\n",
      "\n",
      "[1020 rows x 2 columns], 'original':       SubjectID  aveOralF  aveOralM  Gender    Age                  Ethnicity  \\\n",
      "0      161117-1     36.85     36.59    Male  41-50                      White   \n",
      "1      161117-2     37.00     37.19  Female  31-40  Black or African-American   \n",
      "2      161117-3     37.20     37.34  Female  21-30                      White   \n",
      "3      161117-4     36.85     37.09  Female  21-30  Black or African-American   \n",
      "4      161117-5     36.80     37.04    Male  18-20                      White   \n",
      "...         ...       ...       ...     ...    ...                        ...   \n",
      "1015  180425-05     36.95     36.99  Female  21-25                      Asian   \n",
      "1016  180425-06     37.25     37.19  Female  21-25                      White   \n",
      "1017  180502-01     37.35     37.59  Female  18-20  Black or African-American   \n",
      "1018  180507-01     37.15     37.29    Male  26-30            Hispanic/Latino   \n",
      "1019  180514-01     37.05     37.19  Female  18-20                      White   \n",
      "\n",
      "      T_atm  Humidity  Distance  T_offset1  ...  T_FHCC1  T_FHRC1  T_FHLC1  \\\n",
      "0      24.0      28.0       0.8     0.7025  ...  33.5775  33.4775  33.3725   \n",
      "1      24.0      26.0       0.8     0.7800  ...  34.0325  34.0550  33.6775   \n",
      "2      24.0      26.0       0.8     0.8625  ...  34.9000  34.8275  34.6475   \n",
      "3      24.0      27.0       0.8     0.9300  ...  34.4400  34.4225  34.6550   \n",
      "4      24.0      27.0       0.8     0.8950  ...  35.0900  35.1600  34.3975   \n",
      "...     ...       ...       ...        ...  ...      ...      ...      ...   \n",
      "1015   25.7      50.8       0.6     1.2225  ...  35.1075  35.3475  35.4000   \n",
      "1016   25.7      50.8       0.6     1.4675  ...  35.3100  35.2175  35.2200   \n",
      "1017   28.0      24.3       0.6     0.1300  ...  35.4350  35.2400  35.2275   \n",
      "1018   25.0      39.8       0.6     1.2450  ...  34.8400  35.0200  34.9250   \n",
      "1019   23.8      45.6       0.6     0.8675  ...  34.5475  34.6500  34.6700   \n",
      "\n",
      "      T_FHBC1  T_FHTC1  T_FH_Max1  T_FHC_Max1   T_Max1    T_OR1  T_OR_Max1  \n",
      "0     33.4925  33.0025    34.5300     34.0075  35.6925  35.6350    35.6525  \n",
      "1     33.9700  34.0025    34.6825     34.6600  35.1750  35.0925    35.1075  \n",
      "2     34.8200  34.6700    35.3450     35.2225  35.9125  35.8600    35.8850  \n",
      "3     34.3025  34.9175    35.6025     35.3150  35.7200  34.9650    34.9825  \n",
      "4     34.6700  33.8275    35.4175     35.3725  35.8950  35.5875    35.6175  \n",
      "...       ...      ...        ...         ...      ...      ...        ...  \n",
      "1015  35.1375  35.2750    35.8525     35.7475  36.0675  35.6775    35.7100  \n",
      "1016  35.2075  35.0700    35.7650     35.5525  36.5000  36.4525    36.4900  \n",
      "1017  35.3675  35.3425    36.3750     35.7100  36.5350  35.9650    35.9975  \n",
      "1018  34.7150  34.5950    35.4150     35.3100  35.8600  35.4150    35.4350  \n",
      "1019  34.2150  34.7100    35.1525     35.1175  35.9725  35.8900    35.9175  \n",
      "\n",
      "[1020 rows x 36 columns], 'headers': Index(['SubjectID', 'aveOralF', 'aveOralM', 'Gender', 'Age', 'Ethnicity',\n",
      "       'T_atm', 'Humidity', 'Distance', 'T_offset1', 'Max1R13_1', 'Max1L13_1',\n",
      "       'aveAllR13_1', 'aveAllL13_1', 'T_RC1', 'T_RC_Dry1', 'T_RC_Wet1',\n",
      "       'T_RC_Max1', 'T_LC1', 'T_LC_Dry1', 'T_LC_Wet1', 'T_LC_Max1', 'RCC1',\n",
      "       'LCC1', 'canthiMax1', 'canthi4Max1', 'T_FHCC1', 'T_FHRC1', 'T_FHLC1',\n",
      "       'T_FHBC1', 'T_FHTC1', 'T_FH_Max1', 'T_FHC_Max1', 'T_Max1', 'T_OR1',\n",
      "       'T_OR_Max1'],\n",
      "      dtype='object')}\n"
     ]
    }
   ],
   "source": [
    "print(infrared_thermography_temperature.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Independent Variables: 33\n",
      "Number of Dependent Variables: 2\n",
      "      Gender    Age                  Ethnicity  T_atm  Humidity  Distance  \\\n",
      "0       Male  41-50                      White   24.0      28.0       0.8   \n",
      "1     Female  31-40  Black or African-American   24.0      26.0       0.8   \n",
      "2     Female  21-30                      White   24.0      26.0       0.8   \n",
      "3     Female  21-30  Black or African-American   24.0      27.0       0.8   \n",
      "4       Male  18-20                      White   24.0      27.0       0.8   \n",
      "...      ...    ...                        ...    ...       ...       ...   \n",
      "1015  Female  21-25                      Asian   25.7      50.8       0.6   \n",
      "1016  Female  21-25                      White   25.7      50.8       0.6   \n",
      "1017  Female  18-20  Black or African-American   28.0      24.3       0.6   \n",
      "1018    Male  26-30            Hispanic/Latino   25.0      39.8       0.6   \n",
      "1019  Female  18-20                      White   23.8      45.6       0.6   \n",
      "\n",
      "      T_offset1  Max1R13_1  Max1L13_1  aveAllR13_1  ...  T_FHCC1  T_FHRC1  \\\n",
      "0        0.7025    35.0300    35.3775      34.4000  ...  33.5775  33.4775   \n",
      "1        0.7800    34.5500    34.5200      33.9300  ...  34.0325  34.0550   \n",
      "2        0.8625    35.6525    35.5175      34.2775  ...  34.9000  34.8275   \n",
      "3        0.9300    35.2225    35.6125      34.3850  ...  34.4400  34.4225   \n",
      "4        0.8950    35.5450    35.6650      34.9100  ...  35.0900  35.1600   \n",
      "...         ...        ...        ...          ...  ...      ...      ...   \n",
      "1015     1.2225    35.6425    35.6525      34.8575  ...  35.1075  35.3475   \n",
      "1016     1.4675    35.9825    35.7575      35.4275  ...  35.3100  35.2175   \n",
      "1017     0.1300    36.4075    36.3400      35.8700  ...  35.4350  35.2400   \n",
      "1018     1.2450    35.8150    35.5250      34.2950  ...  34.8400  35.0200   \n",
      "1019     0.8675    35.7075    35.5825      34.8875  ...  34.5475  34.6500   \n",
      "\n",
      "      T_FHLC1  T_FHBC1  T_FHTC1  T_FH_Max1  T_FHC_Max1   T_Max1    T_OR1  \\\n",
      "0     33.3725  33.4925  33.0025    34.5300     34.0075  35.6925  35.6350   \n",
      "1     33.6775  33.9700  34.0025    34.6825     34.6600  35.1750  35.0925   \n",
      "2     34.6475  34.8200  34.6700    35.3450     35.2225  35.9125  35.8600   \n",
      "3     34.6550  34.3025  34.9175    35.6025     35.3150  35.7200  34.9650   \n",
      "4     34.3975  34.6700  33.8275    35.4175     35.3725  35.8950  35.5875   \n",
      "...       ...      ...      ...        ...         ...      ...      ...   \n",
      "1015  35.4000  35.1375  35.2750    35.8525     35.7475  36.0675  35.6775   \n",
      "1016  35.2200  35.2075  35.0700    35.7650     35.5525  36.5000  36.4525   \n",
      "1017  35.2275  35.3675  35.3425    36.3750     35.7100  36.5350  35.9650   \n",
      "1018  34.9250  34.7150  34.5950    35.4150     35.3100  35.8600  35.4150   \n",
      "1019  34.6700  34.2150  34.7100    35.1525     35.1175  35.9725  35.8900   \n",
      "\n",
      "      T_OR_Max1  \n",
      "0       35.6525  \n",
      "1       35.1075  \n",
      "2       35.8850  \n",
      "3       34.9825  \n",
      "4       35.6175  \n",
      "...         ...  \n",
      "1015    35.7100  \n",
      "1016    36.4900  \n",
      "1017    35.9975  \n",
      "1018    35.4350  \n",
      "1019    35.9175  \n",
      "\n",
      "[1020 rows x 33 columns]       aveOralF  aveOralM\n",
      "0        36.85     36.59\n",
      "1        37.00     37.19\n",
      "2        37.20     37.34\n",
      "3        36.85     37.09\n",
      "4        36.80     37.04\n",
      "...        ...       ...\n",
      "1015     36.95     36.99\n",
      "1016     37.25     37.19\n",
      "1017     37.35     37.59\n",
      "1018     37.15     37.29\n",
      "1019     37.05     37.19\n",
      "\n",
      "[1020 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Independent Variables: {X.shape[1]}\")\n",
    "print(f\"Number of Dependent Variables: {y.shape[1]}\")\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Is it possible to apply linear regression?\n",
    "\n",
    "In this dataset, we have non-numeric data such as age ranges, sex, and other categorical variables. To apply linear regression to these types of data, they need to be converted into a numerical format. This can be achieved using the following methods:\n",
    "\n",
    "1. **Label Encoding**: Assigns a unique integer to each category. This is suitable for ordinal data where categories have a meaningful order, such as 'low', 'medium', and 'high'.\n",
    "\n",
    "2. **One-Hot Encoding**: Creates binary columns for each category, indicating the presence or absence of each category. This method is ideal for nominal data without an inherent order, such as 'sex' or 'ethnicity'.\n",
    "\n",
    "3. **Ordinal Encoding**: Assigns integer values to categories based on their inherent order. This method is appropriate for ordinal variables where the sequence of categories carries significance, such as 'age ranges'.\n",
    "\n",
    "4. **Binning**: Converts continuous variables into discrete categories or bins. This is useful for grouping continuous data, like 'age', into meaningful ranges.\n",
    "\n",
    "By employing these encoding techniques, non-numeric data can be effectively transformed into a numerical format suitable for linear regression analysis.\n",
    "\n",
    "**If the dataset doesn't meet these criteria, preprocessing steps could include:**\n",
    "- Checking for and transforming non-linear relationships.\n",
    "- Using techniques like PCA to address multicollinearity.\n",
    "- Scaling features if needed.\n",
    "- Removing outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Handling NaN/Missing Values\n",
    "\n",
    "The provided code is not correct. Because we must remove both the X and y values corresponding to a missing value.\n",
    "\n",
    "table.dropna() ensures that we remove rows with any missing values across the entire dataset, maintaining consistency and alignment.\n",
    "X.dropna() and y.dropna() separately might lead to mismatched data and additional complexity, especially when dealing with feature and target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Gender         0\n",
      "Age            0\n",
      "Ethnicity      0\n",
      "T_atm          0\n",
      "Humidity       0\n",
      "Distance       2\n",
      "T_offset1      0\n",
      "Max1R13_1      0\n",
      "Max1L13_1      0\n",
      "aveAllR13_1    0\n",
      "aveAllL13_1    0\n",
      "T_RC1          0\n",
      "T_RC_Dry1      0\n",
      "T_RC_Wet1      0\n",
      "T_RC_Max1      0\n",
      "T_LC1          0\n",
      "T_LC_Dry1      0\n",
      "T_LC_Wet1      0\n",
      "T_LC_Max1      0\n",
      "RCC1           0\n",
      "LCC1           0\n",
      "canthiMax1     0\n",
      "canthi4Max1    0\n",
      "T_FHCC1        0\n",
      "T_FHRC1        0\n",
      "T_FHLC1        0\n",
      "T_FHBC1        0\n",
      "T_FHTC1        0\n",
      "T_FH_Max1      0\n",
      "T_FHC_Max1     0\n",
      "T_Max1         0\n",
      "T_OR1          0\n",
      "T_OR_Max1      0\n",
      "aveOralF       0\n",
      "aveOralM       0\n",
      "dtype: int64\n",
      "Total number of missing values in the DataFrame: 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = pd.concat([X, y], axis = 1)\n",
    "# Count missing values for each column\n",
    "missing_values_per_column = table.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values_per_column)\n",
    "# Count the total number of missing values in the DataFrame\n",
    "total_missing_values = table.isnull().sum().sum()\n",
    "print(f\"Total number of missing values in the DataFrame: {total_missing_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Gender         0\n",
      "Age            0\n",
      "Ethnicity      0\n",
      "T_atm          0\n",
      "Humidity       0\n",
      "Distance       0\n",
      "T_offset1      0\n",
      "Max1R13_1      0\n",
      "Max1L13_1      0\n",
      "aveAllR13_1    0\n",
      "aveAllL13_1    0\n",
      "T_RC1          0\n",
      "T_RC_Dry1      0\n",
      "T_RC_Wet1      0\n",
      "T_RC_Max1      0\n",
      "T_LC1          0\n",
      "T_LC_Dry1      0\n",
      "T_LC_Wet1      0\n",
      "T_LC_Max1      0\n",
      "RCC1           0\n",
      "LCC1           0\n",
      "canthiMax1     0\n",
      "canthi4Max1    0\n",
      "T_FHCC1        0\n",
      "T_FHRC1        0\n",
      "T_FHLC1        0\n",
      "T_FHBC1        0\n",
      "T_FHTC1        0\n",
      "T_FH_Max1      0\n",
      "T_FHC_Max1     0\n",
      "T_Max1         0\n",
      "T_OR1          0\n",
      "T_OR_Max1      0\n",
      "aveOralF       0\n",
      "aveOralM       0\n",
      "dtype: int64\n",
      "Total number of missing values in the DataFrame: 0\n"
     ]
    }
   ],
   "source": [
    "# Count missing values for each column\n",
    "missing_values_per_column = table.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values_per_column)\n",
    "# Count the total number of missing values in the DataFrame\n",
    "total_missing_values = table.isnull().sum().sum()\n",
    "print(f\"Total number of missing values in the DataFrame: {total_missing_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. and 6. Selecting Features and Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age    T_OR1  T_OR_Max1  T_FHC_Max1  T_FH_Max1\n",
      "0     41-50  35.6350    35.6525     34.0075    34.5300\n",
      "1     31-40  35.0925    35.1075     34.6600    34.6825\n",
      "2     21-30  35.8600    35.8850     35.2225    35.3450\n",
      "3     21-30  34.9650    34.9825     35.3150    35.6025\n",
      "4     18-20  35.5875    35.6175     35.3725    35.4175\n",
      "...     ...      ...        ...         ...        ...\n",
      "1015  21-25  35.6775    35.7100     35.7475    35.8525\n",
      "1016  21-25  36.4525    36.4900     35.5525    35.7650\n",
      "1017  18-20  35.9650    35.9975     35.7100    36.3750\n",
      "1018  26-30  35.4150    35.4350     35.3100    35.4150\n",
      "1019  18-20  35.8900    35.9175     35.1175    35.1525\n",
      "\n",
      "[1020 rows x 5 columns]       aveOralM\n",
      "0        36.59\n",
      "1        37.19\n",
      "2        37.34\n",
      "3        37.09\n",
      "4        37.04\n",
      "...        ...\n",
      "1015     36.99\n",
      "1016     37.19\n",
      "1017     37.59\n",
      "1018     37.29\n",
      "1019     37.19\n",
      "\n",
      "[1020 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Selecting 'aveOralM' as the dependent variable\n",
    "y = y[['aveOralM']]\n",
    "\n",
    "# Selecting 'Age' and four other features based on preference\n",
    "X = X[['Age', 'T_OR1', 'T_OR_Max1', 'T_FHC_Max1', 'T_FH_Max1']]\n",
    "\n",
    "print(X,y)\n",
    "\n",
    "# Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Training a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'T_OR1', 'T_OR_Max1', 'T_FHC_Max1', 'T_FH_Max1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       41-50\n",
      "1       31-40\n",
      "2       21-30\n",
      "3       21-30\n",
      "4       18-20\n",
      "        ...  \n",
      "1015    21-25\n",
      "1016    21-25\n",
      "1017    18-20\n",
      "1018    26-30\n",
      "1019    18-20\n",
      "Name: Age, Length: 1020, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_age_range(age_range):\n",
    "    \"\"\"Converts the age range to a single average value\"\"\"\n",
    "    if '>' in age_range:\n",
    "        return int(age_range.replace('>', '').strip())\n",
    "    lower, upper = map(int, age_range.split('-'))\n",
    "    return (lower + upper) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       45.5\n",
      "1       35.5\n",
      "2       25.5\n",
      "3       25.5\n",
      "4       19.0\n",
      "        ... \n",
      "1015    23.0\n",
      "1016    23.0\n",
      "1017    19.0\n",
      "1018    28.0\n",
      "1019    19.0\n",
      "Name: Age, Length: 1020, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_27752\\2353021610.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.Age = X.Age.apply(convert_age_range)\n"
     ]
    }
   ],
   "source": [
    "X.Age = X.Age.apply(convert_age_range)\n",
    "print(X.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Coefficients: [[ 0.00113644  0.05647584  0.49937613 -0.08398371  0.36994022]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Coefficients corresponding to independent variables\n",
    "coefficients = model.coef_\n",
    "print(f\"Estimated Coefficients: {coefficients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Identifying the Most Contributing Variable\n",
    "The variable with the highest absolute value in the coefficient array contributes the most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most contributing feature: T_OR_Max1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_contributor_index = np.argmax(np.abs(coefficients))\n",
    "most_contributing_feature = X.columns[max_contributor_index]\n",
    "print(f\"Most contributing feature: {most_contributing_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Additional Feature Selection and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        T_OR1  T_OR_Max1  T_FHC_Max1  T_FH_Max1\n",
      "0     35.6350    35.6525     34.0075    34.5300\n",
      "1     35.0925    35.1075     34.6600    34.6825\n",
      "2     35.8600    35.8850     35.2225    35.3450\n",
      "3     34.9650    34.9825     35.3150    35.6025\n",
      "4     35.5875    35.6175     35.3725    35.4175\n",
      "...       ...        ...         ...        ...\n",
      "1015  35.6775    35.7100     35.7475    35.8525\n",
      "1016  36.4525    36.4900     35.5525    35.7650\n",
      "1017  35.9650    35.9975     35.7100    36.3750\n",
      "1018  35.4150    35.4350     35.3100    35.4150\n",
      "1019  35.8900    35.9175     35.1175    35.1525\n",
      "\n",
      "[1020 rows x 4 columns]\n",
      "Estimated Coefficients: [[ 0.09199696  0.4640698  -0.08733171  0.37088645]]\n"
     ]
    }
   ],
   "source": [
    "X = X[['T_OR1', 'T_OR_Max1', 'T_FHC_Max1', 'T_FH_Max1']]\n",
    "print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "coefficients = model.coef_\n",
    "print(f\"Estimated Coefficients: {coefficients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Calculating Statistical Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS: aveOralM    15.170504\n",
      "dtype: float64\n",
      "RSE: aveOralM    0.276104\n",
      "dtype: float64\n",
      "MSE: 0.07436521744807979\n",
      "R-squared: 0.6468420800555861\n",
      "Standard Errors: const         0.803926\n",
      "T_OR1         0.883501\n",
      "T_OR_Max1     0.882069\n",
      "T_FHC_Max1    0.044464\n",
      "T_FH_Max1     0.049258\n",
      "dtype: float64\n",
      "t-statistics: const         8.753146\n",
      "T_OR1         0.104128\n",
      "T_OR_Max1     0.526115\n",
      "T_FHC_Max1   -1.964102\n",
      "T_FH_Max1     7.529419\n",
      "dtype: float64\n",
      "p-values: const         1.191574e-17\n",
      "T_OR1         9.170938e-01\n",
      "T_OR_Max1     5.989521e-01\n",
      "T_FHC_Max1    4.985945e-02\n",
      "T_FH_Max1     1.358512e-13\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Residual sum of squares (RSS)\n",
    "y_pred = model.predict(X_test)\n",
    "RSS = np.sum(np.square(y_test - y_pred))\n",
    "\n",
    "# Residual Standard Error (RSE)\n",
    "N = len(y_test)\n",
    "d = X_train.shape[1]\n",
    "RSE = np.sqrt(RSS / (N - d - 1))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# R-squared statistic\n",
    "R_squared = model.score(X_test, y_test)\n",
    "\n",
    "# Standard Error, t-statistic, p-value\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_with_const = sm.add_constant(X_train)\n",
    "ols_model = sm.OLS(y_train, X_train_with_const).fit()\n",
    "standard_errors = ols_model.bse\n",
    "t_statistics = ols_model.tvalues\n",
    "p_values = ols_model.pvalues\n",
    "\n",
    "print(f\"RSS: {RSS}\")\n",
    "print(f\"RSE: {RSE}\")\n",
    "print(f\"MSE: {MSE}\")\n",
    "print(f\"R-squared: {R_squared}\")\n",
    "print(f\"Standard Errors: {standard_errors}\")\n",
    "print(f\"t-statistics: {t_statistics}\")\n",
    "print(f\"p-values: {p_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Significant and Insignificant features\n",
    "In linear regression, we consider a feature significant if its p-value is less than 0.05. Conversely, if the p-value is greater than or equal to 0.05, we regard the feature as insignificant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant Features: const         1.191574e-17\n",
      "T_FHC_Max1    4.985945e-02\n",
      "T_FH_Max1     1.358512e-13\n",
      "dtype: float64\n",
      "Insignificant Features: T_OR1        0.917094\n",
      "T_OR_Max1    0.598952\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "significant_features = p_values[p_values < 0.05]\n",
    "insignificant_features = p_values[p_values >= 0.05]\n",
    "\n",
    "print(f\"Significant Features: {significant_features}\")\n",
    "print(f\"Insignificant Features: {insignificant_features}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
